{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitbasee0e66f8e4cdf4b30a175922b5b25ea0e",
   "display_name": "Python 3.8.3 64-bit ('base')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "plt.rcParams['axes.edgecolor']='white'\n",
    "plt.rcParams['figure.facecolor']='white'\n",
    "plt.rcParams['savefig.facecolor']='white'"
   ]
  },
  {
   "source": [
    "Load the PDBbind training set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_training_set_pk = pd.read_csv('../data/pdbbind_training_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)\n",
    "pdbbind_training_set = pdbbind_training_set_pk.index\n",
    "\n",
    "docked_pose_features = pd.read_csv('../data/docked_pose_features.csv', index_col=0)\n",
    "\n",
    "feature_sets = {}\n",
    "with open('../data/lb_feature_names.txt') as f:\n",
    "    feature_sets['LB'] = pd.Index([l.strip() for l in f])\n",
    "with open('../data/sb_feature_names.txt') as f:\n",
    "    feature_sets['SB'] = pd.Index([l.strip() for l in f])\n",
    "with open('../data/hb_feature_names.txt') as f:\n",
    "    feature_sets['HB'] = pd.Index([l.strip() for l in f])\n",
    "\n",
    "# List the pose labels corresponding to the docked poses in the training and test sets\n",
    "with open('../data/docked_pose_labels.json') as f:\n",
    "    docked_pose_labels = json.load(f)\n",
    "\n",
    "pdbbind_training_set_labels = []\n",
    "for pdb in pdbbind_training_set:\n",
    "    pdbbind_training_set_labels.extend(docked_pose_labels[pdb])\n",
    "pdbbind_training_set_labels = pd.Index(pdbbind_training_set_labels)"
   ]
  },
  {
   "source": [
    "Load the updated DUD-E diverse set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['AKT1', 'CP3A4', 'GCR', 'HIVPR', 'HIVRT', 'KIF11']\n",
    "docked_features = {}\n",
    "ligand_features = {}\n",
    "for target in targets:\n",
    "    with open(f'../data/{target}_KI_docked_features.json') as f:\n",
    "        docked_features[target] = json.load(f)\n",
    "    with open(f'../data/{target}_KI_rdkit_descriptors.json') as f:\n",
    "        ligand_features[target] = json.load(f)\n",
    "\n",
    "# Concatenate structure-based and ligand-based features\n",
    "features = {}\n",
    "for target in targets:\n",
    "    features[target] = {}\n",
    "    for label in docked_features[target]:\n",
    "        features[target][label] = {**docked_features[target][label], **ligand_features[target][label.split('_')[0]]}\n",
    "features = {target: pd.DataFrame(features[target]).T for target in features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_data = {}\n",
    "for target in targets:\n",
    "    df = pd.read_csv(f'../data/{target}_KI_clean.csv', index_col=0)\n",
    "    binding_data[target] = df['pChEMBL Value']"
   ]
  },
  {
   "source": [
    "### Distribution of binding data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2,figsize=(12, 18))\n",
    "axes = axes.flatten()\n",
    "annots = iter(['A', 'B', 'C', 'D', 'E', 'F'])\n",
    "for target, ax in zip(targets, axes):\n",
    "    data = binding_data[target].values.ravel()\n",
    "    xmin = int(min(data))\n",
    "    xmax = int(max(data))+1\n",
    "    ax.hist(data, bins=np.arange(xmin, xmax+1, 1), alpha=0.5)\n",
    "    ax.set_title(target)\n",
    "    ax.text(-0.1, 1.1, next(annots), transform=ax.transAxes, size=20, weight='bold')\n",
    "    ax.set_xlabel('pChEMBL value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "fig.tight_layout()\n",
    "#fig.savefig('../figures/chembl_data_distribution.pdf', dpi=350, bbox_inches='tight')"
   ]
  },
  {
   "source": [
    "Get the labels of the pose ranked highest by Smina for each ligand."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "base_ids = {}\n",
    "conformer_ids = {}\n",
    "for target in targets:\n",
    "    labels = features[target].index\n",
    "    base_ids[target] = []\n",
    "    conformer_ids[target] = {}\n",
    "    for label in labels:\n",
    "        base_id = label.split('_')[0]\n",
    "        if base_id in conformer_ids[target]:\n",
    "            conformer_ids[target][base_id].append(label)\n",
    "        else:\n",
    "            conformer_ids[target][base_id] = [label]\n",
    "\n",
    "dude_top_docked_poses = {}\n",
    "\n",
    "for target in targets:\n",
    "    dude_top_docked_poses[target] = pd.Index([conformer_ids[target][base_id][0] for base_id in conformer_ids[target]])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Inter-target validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_target_pred = {}\n",
    "for target in targets:\n",
    "    inter_target_pred[target] = {}\n",
    "    training_targets = [t for t in targets if t != target]\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for t in training_targets:\n",
    "        X = features[t].loc[dude_top_docked_poses[t]]\n",
    "        idx = pd.Index([i.split('_')[0] for i in X.index])\n",
    "        X.index = idx\n",
    "        y = binding_data[t].loc[idx]\n",
    "        X_train.append(X)\n",
    "        y_train.append(y)\n",
    "    X_train = pd.concat(X_train, axis='index')\n",
    "    y_train = pd.concat(y_train, axis='index')\n",
    "    \n",
    "    for f in feature_sets:\n",
    "        rf= RandomForestRegressor(n_estimators=500, max_features=0.33, oob_score=True, random_state=42, n_jobs=32)\n",
    "        rf.fit(X_train.loc[:, feature_sets[f]], y_train)\n",
    "\n",
    "        X_test = features[target].loc[:, feature_sets[f]]\n",
    "        inter_target_pred[target][f] = pd.Series(index=X_test.index, data=rf.predict(X_test))"
   ]
  }
 ]
}