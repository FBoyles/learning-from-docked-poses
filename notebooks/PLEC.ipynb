{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes PLEC fingerprints for PDBbind and DUD-E/ChEMBL data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oddt.scoring.descriptors import universal_descriptor\n",
    "from oddt.fingerprints import PLEC, sparse_to_csr_matrix, csr_matrix_to_sparse, fold, sparse_to_dense\n",
    "from oddt.toolkits import rdk, ob\n",
    "\n",
    "from statistical_tests import bootstrap_pearsonr, permutation_pearsonr\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from joblib import delayed, Parallel\n",
    "from functools import partial\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy import sparse, stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "PDBBIND_DIR = '/home/fergus/pdbbind/v2019' # point to top-level directory of pdbbind database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_training_set.txt') as f:\n",
    "    train_pdbs = [l.strip() for l in f]\n",
    "    \n",
    "with open('../data/pdbbind_test_set.txt') as f:\n",
    "    test_pdbs = [l.strip() for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed # helper for parallel plec fingerprint calculation\n",
    "def build(pdb):\n",
    "    protein = next(ob.readfile('pdb', f'{PDBBIND_DIR}/{pdb}/{pdb}_protein.pdb'))\n",
    "    protein.protein = True\n",
    "    # crystal\n",
    "    ligand = next(ob.readfile('sdf', f'{PDBBIND_DIR}/{pdb}/{pdb}_ligand.sdf'))\n",
    "    features_c = PLEC(ligand, protein, depth_ligand=1, depth_protein=5, size=65536, count_bits=True, sparse=True, ignore_hoh=True)\n",
    "    # docked        \n",
    "    ligand = next(ob.readfile('sdf', f'../pdbbind_docked_poses/{pdb}/{pdb}_ligand_docked.sdf'))\n",
    "    features_d = PLEC(ligand, protein, depth_ligand=1, depth_protein=5, size=65536, count_bits=True, sparse=True, ignore_hoh=True)\n",
    "    return (features_c, features_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   40.3s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=6)]: Done 601 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=6)]: Done 673 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=6)]: Done 710 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=6)]: Done 749 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=6)]: Done 829 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=6)]: Done 913 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=6)]: Done 956 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=6)]: Done 1046 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=6)]: Done 1093 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=6)]: Done 1189 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=6)]: Done 1289 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=6)]: Done 1340 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=6)]: Done 1393 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed: 17.0min\n",
      "[Parallel(n_jobs=6)]: Done 1501 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=6)]: Done 1556 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=6)]: Done 1613 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=6)]: Done 1670 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=6)]: Done 1729 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=6)]: Done 1849 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=6)]: Done 1910 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=6)]: Done 1973 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=6)]: Done 2036 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=6)]: Done 2101 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=6)]: Done 2166 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=6)]: Done 2233 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=6)]: Done 2300 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=6)]: Done 2369 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=6)]: Done 2509 tasks      | elapsed: 32.5min\n",
      "[Parallel(n_jobs=6)]: Done 2580 tasks      | elapsed: 34.2min\n",
      "[Parallel(n_jobs=6)]: Done 2653 tasks      | elapsed: 35.1min\n",
      "[Parallel(n_jobs=6)]: Done 2726 tasks      | elapsed: 36.4min\n",
      "[Parallel(n_jobs=6)]: Done 2801 tasks      | elapsed: 37.0min\n",
      "[Parallel(n_jobs=6)]: Done 2876 tasks      | elapsed: 37.6min\n",
      "[Parallel(n_jobs=6)]: Done 2953 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=6)]: Done 3030 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=6)]: Done 3109 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed: 39.5min\n",
      "[Parallel(n_jobs=6)]: Done 3269 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=6)]: Done 3350 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=6)]: Done 3433 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=6)]: Done 3516 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=6)]: Done 3601 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=6)]: Done 3686 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=6)]: Done 3752 out of 3752 | elapsed: 42.5min finished\n"
     ]
    }
   ],
   "source": [
    "plecs_xtal = {}\n",
    "\n",
    "with Parallel(n_jobs=6, verbose=10) as parallel:\n",
    "    plecs_xtal = parallel(build_plec(pdb) for pdb in pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_training_set_docked_plec_sparse.json', 'w') as f:\n",
    "    json.dump(plecs, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_training_set_crystal_plec_sparse.json', 'w') as f:\n",
    "    json.dump(plecs_xtal, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "x_docked = []\n",
    "x_crystal = []\n",
    "labels = []\n",
    "for plec_docked, plec_crystal, pdb in zip(plecs, plecs_xtal, pdbs):\n",
    "    y.append(1)\n",
    "    x_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "    x_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "    labels.append(pdb)\n",
    "    #x.append(sparse_to_dense(plec, size=65536).tolist())\n",
    "x_crystal = sparse.vstack(x_crystal, format='csr')\n",
    "x_docked = sparse.vstack(x_docked, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=6)]: Done 519 out of 519 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "with Parallel(n_jobs=6, verbose=10) as parallel:\n",
    "    test_features = parallel(build(pdb) for pdb in test_pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features_crystal = {}\n",
    "test_features_docked = {}\n",
    "\n",
    "for feature, pdb in zip(test_features, test_pdbs):\n",
    "    test_features_crystal[pdb] = feature[0]\n",
    "    test_features_docked[pdb] = feature[1]\n",
    "    \n",
    "with open('../data/pdbbind_test_set_docked_plec_sparse.json', 'w') as f:\n",
    "    json.dump(test_features_docked, f, cls=NumpyEncoder)\n",
    "    \n",
    "with open('../data/pdbbind_test_set_crystal_plec_sparse.json', 'w') as f:\n",
    "    json.dump(test_features_crystal, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_training_set_docked_plec_sparse.json') as f:\n",
    "    train_features_docked = json.load(f)\n",
    "    \n",
    "with open('../data/pdbbind_training_set_crystal_plec_sparse.json') as f:\n",
    "    train_features_crystal = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_test_set_docked_plec_sparse.json') as f:\n",
    "    test_features_docked = json.load(f)\n",
    "    \n",
    "with open('../data/pdbbind_test_set_crystal_plec_sparse.json') as f:\n",
    "    test_features_crystal = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in train_features_crystal], format='csr')\n",
    "X_test_sparse = sparse.vstack([sparse_to_csr_matrix(test_features_crystal[pdb], size=65536) for pdb in test_features_crystal], format='csr')\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_sparse)\n",
    "X_train_svd = svd.transform(X_train_sparse)\n",
    "X_test_svd = svd.transform(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_affinity = pd.read_csv('../data/pdbbind_training_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)\n",
    "test_affinity = pd.read_csv('../data/pdbbind_test_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "X_train_crystal = []\n",
    "X_train_docked = []\n",
    "labels = []\n",
    "for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, train_pdbs):\n",
    "    X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "    X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "    y_train.append(train_affinity.loc[pdb])\n",
    "X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "X_train_docked = sparse.vstack(X_train_docked, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "X_test_crystal = []\n",
    "X_test_docked = []\n",
    "labels = []\n",
    "for pdb in test_pdbs:\n",
    "    X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "    X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    y_test.append(test_affinity.loc[pdb])\n",
    "X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "X_test_docked = sparse.vstack(X_test_docked, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 54min 36s, sys: 9.37 s, total: 1h 54min 45s\n",
      "Wall time: 15min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=0.33, n_estimators=500, n_jobs=8,\n",
       "                      oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "rf_crystal.fit(X_train_crystal, y_train)\n",
    "rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "rf_docked.fit(X_train_docked, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_crystal = rf_crystal.predict(X_test_crystal)\n",
    "predicted_docked = rf_docked.predict(X_test_docked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42min 54s, sys: 3 s, total: 42min 57s\n",
      "Wall time: 5min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=8, oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# using original plecscore params\n",
    "plecscore_crystal = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=8, oob_score=True)\n",
    "plecscore_crystal.fit(X_train_crystal, y_train)\n",
    "plecscore_docked = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=8, oob_score=True)\n",
    "plecscore_docked.fit(X_train_docked, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_plecscore_crystal = plecscore_crystal.predict(X_test_crystal)\n",
    "predicted_plecscore_docked = plecscore_docked.predict(X_test_docked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_training_set = pd.Index(train_pdbs)\n",
    "pdbbind_test_set = pd.Index(test_pdbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_clusters = {}\n",
    "for cutoff in [30, 40, 50, 70, 90, 95, 100]:\n",
    "    with open(f'../data/bc-{cutoff}.out') as f:\n",
    "        blast_clusters[cutoff] = [set(item[:4].lower() for item in line.strip().split()) for line in f]\n",
    "\n",
    "test_set_similar_pdbs = {}\n",
    "for cutoff in blast_clusters:\n",
    "    pdbs = set()\n",
    "    for pdb in pdbbind_test_set:\n",
    "        for cluster in blast_clusters[cutoff]:\n",
    "            if pdb in cluster:\n",
    "                pdbs.update(cluster)\n",
    "    test_set_similar_pdbs[cutoff] = pd.Index(pdbs).intersection(pdbbind_training_set)\n",
    "\n",
    "test_set_similar_pdbs['All'] = pd.Index([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pdbbind_ligand_tanimoto_similarity.json') as f:\n",
    "    tanimoto_similarity = json.load(f)\n",
    "\n",
    "tc_thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "test_set_similar_ligands = {}\n",
    "\n",
    "for t in tc_thresholds:\n",
    "    similar = set()\n",
    "    for pdb_test in pdbbind_test_set:\n",
    "        for pdb_train in pdbbind_training_set:\n",
    "            if pdb_train in similar:\n",
    "                continue\n",
    "            if tanimoto_similarity[pdb_test][pdb_train] >= t:\n",
    "                similar.add(pdb_train)\n",
    "    test_set_similar_ligands[t] = pd.Index(similar)\n",
    "test_set_similar_ligands['All'] = pd.Index([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "X_train_crystal = []\n",
    "X_train_docked = []\n",
    "labels = []\n",
    "for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, train_pdbs):\n",
    "    X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "    X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "    y_train.append(train_affinity.loc[pdb])\n",
    "X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "X_train_docked = sparse.vstack(X_train_docked, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "X_test_crystal = []\n",
    "X_test_docked = []\n",
    "labels = []\n",
    "for pdb in test_pdbs:\n",
    "    X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "    X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    y_test.append(test_affinity.loc[pdb])\n",
    "X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "X_test_docked = sparse.vstack(X_test_docked, format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "40\n",
      "50\n",
      "70\n",
      "90\n",
      "95\n",
      "100\n",
      "All\n",
      "CPU times: user 7h 17min 48s, sys: 19.3 s, total: 7h 18min 8s\n",
      "Wall time: 59min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_crystal_sequence_identity = {}\n",
    "predicted_docked_sequence_identity = {}\n",
    "pearsonr_crystal_sequence_identity = {}\n",
    "pearsonr_docked_sequence_identity = {}\n",
    "\n",
    "X_test_crystal = []\n",
    "X_test_docked = []\n",
    "y_test = []\n",
    "for pdb in pdbbind_test_set:\n",
    "    X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "    X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    y_test.append(test_affinity.loc[pdb])\n",
    "X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "X_test_docked = sparse.vstack(X_test_docked, format='csr')\n",
    "\n",
    "for cutoff in test_set_similar_pdbs:\n",
    "    print(cutoff)\n",
    "    y_train = []\n",
    "    X_train_crystal = []\n",
    "    X_train_docked = []\n",
    "    for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, pdbbind_training_set):\n",
    "        if pdb in test_set_similar_pdbs[cutoff]:\n",
    "            continue\n",
    "        X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "        X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "        y_train.append(train_affinity.loc[pdb])\n",
    "    X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "    X_train_docked = sparse.vstack(X_train_docked, format='csr')\n",
    "    \n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_crystal_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_crystal)}\n",
    "    predicted_docked_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_docked)}\n",
    "    \n",
    "    pearsonr_crystal_sequence_identity[cutoff] = stats.pearsonr(y_test, predicted_crystal)[0]\n",
    "    pearsonr_docked_sequence_identity[cutoff] = stats.pearsonr(y_test, predicted_docked)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.0\n",
      "All\n",
      "CPU times: user 13h 22min 35s, sys: 2min 36s, total: 13h 25min 12s\n",
      "Wall time: 1h 59min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicted_crystal_tanimoto = {}\n",
    "predicted_docked_tanimoto = {}\n",
    "pearsonr_crystal_tanimoto = {}\n",
    "pearsonr_docked_tanimoto = {}\n",
    "\n",
    "X_test_crystal = []\n",
    "X_test_docked = []\n",
    "y_test = []\n",
    "for pdb in pdbbind_test_set:\n",
    "    X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "    X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    y_test.append(test_affinity.loc[pdb])\n",
    "X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "X_test_docked = sparse.vstack(X_test_docked, format='csr')\n",
    "\n",
    "for cutoff in test_set_similar_ligands:\n",
    "    print(cutoff)\n",
    "    y_train = []\n",
    "    X_train_crystal = []\n",
    "    X_train_docked = []\n",
    "    for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, pdbbind_training_set):\n",
    "        if pdb in test_set_similar_ligands[cutoff]:\n",
    "            continue\n",
    "        X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "        X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "        y_train.append(train_affinity.loc[pdb])\n",
    "    X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "    X_train_docked = sparse.vstack(X_train_docked, format='csr')\n",
    "    \n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_crystal_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_crystal)}\n",
    "    predicted_docked_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_docked)}\n",
    "    \n",
    "    pearsonr_crystal_tanimoto[cutoff] = stats.pearsonr(y_test, predicted_crystal)[0]\n",
    "    pearsonr_docked_tanimoto[cutoff] = stats.pearsonr(y_test, predicted_docked)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PLEC_predicted_crystal_sequence_identity.json', 'w') as f:\n",
    "    json.dump(predicted_crystal_sequence_identity, f, cls=NumpyEncoder)\n",
    "with open('PLEC_predicted_docked_sequence_identity.json', 'w') as f:\n",
    "    json.dump(predicted_docked_sequence_identity, f, cls=NumpyEncoder)\n",
    "with open('PLEC_pearsonr_crystal_sequence_identity.json', 'w') as f:\n",
    "    json.dump(pearsonr_crystal_sequence_identity, f, cls=NumpyEncoder)\n",
    "with open('PLEC_pearsonr_docked_sequence_identity.json', 'w') as f:\n",
    "    json.dump(pearsonr_docked_sequence_identity, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PLEC_predicted_crystal_tanimoto.json', 'w') as f:\n",
    "    json.dump(predicted_crystal_tanimoto, f, cls=NumpyEncoder)\n",
    "with open('PLEC_predicted_docked_tanimoto.json', 'w') as f:\n",
    "    json.dump(predicted_docked_tanimoto, f, cls=NumpyEncoder)\n",
    "with open('PLEC_pearsonr_crystal_tanimoto.json', 'w') as f:\n",
    "    json.dump(pearsonr_crystal_tanimoto, f, cls=NumpyEncoder)\n",
    "with open('PLEC_pearsonr_docked_tanimoto.json', 'w') as f:\n",
    "    json.dump(pearsonr_docked_tanimoto, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PLEC_predicted_crystal_sequence_identity.json') as f:\n",
    "    predicted_crystal_sequence_identity = json.load(f)\n",
    "with open('PLEC_predicted_docked_sequence_identity.json') as f:\n",
    "    predicted_docked_sequence_identity = json.load(f)\n",
    "with open('PLEC_pearsonr_crystal_sequence_identity.json') as f:\n",
    "    pearsonr_crystal_sequence_identity = json.load(f)\n",
    "with open('PLEC_pearsonr_docked_sequence_identity.json') as f:\n",
    "    pearsonr_docked_sequence_identity = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PLEC_predicted_crystal_tanimoto.json') as f:\n",
    "    predicted_crystal_tanimoto = json.load(f)\n",
    "with open('PLEC_predicted_docked_tanimoto.json') as f:\n",
    "    predicted_docked_tanimoto = json.load(f)\n",
    "with open('PLEC_pearsonr_crystal_tanimoto.json') as f:\n",
    "    pearsonr_crystal_tanimoto = json.load(f)\n",
    "with open('PLEC_pearsonr_docked_tanimoto.json') as f:\n",
    "    pearsonr_docked_tanimoto = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistical_tests as st\n",
    "\n",
    "pearsonr_ci_crystal_si = {}\n",
    "pearsonr_ci_docked_si = {}\n",
    "pearsonr_pval_crystal_si = {}\n",
    "pearsonr_pval_docked_si = {}\n",
    "pearsonr_ci_crystal_tc = {}\n",
    "pearsonr_ci_docked_tc = {}\n",
    "pearsonr_pval_crystal_tc = {}\n",
    "pearsonr_pval_docked_tc = {}\n",
    "\n",
    "y_test = test_affinity.loc[pdbbind_test_set]\n",
    "for cutoff in predicted_crystal_sequence_identity:\n",
    "    y_pred = pd.Series(predicted_crystal_sequence_identity[cutoff]).loc[pdbbind_test_set]\n",
    "    pearsonr_ci_crystal_si[cutoff] = st.bootstrap_pearsonr(y_test, y_pred)\n",
    "    pearsonr_pval_crystal_si[cutoff] = st.permutation_pearsonr(y_test, y_pred)\n",
    "    y_pred = pd.Series(predicted_docked_sequence_identity[cutoff]).loc[pdbbind_test_set]\n",
    "    pearsonr_pval_docked_si[cutoff] = st.permutation_pearsonr(y_test, y_pred)\n",
    "    pearsonr_ci_docked_si[cutoff] = st.bootstrap_pearsonr(y_test, y_pred)\n",
    "\n",
    "for cutoff in predicted_crystal_tanimoto:\n",
    "    y_pred = pd.Series(predicted_crystal_tanimoto[cutoff]).loc[pdbbind_test_set]\n",
    "    pearsonr_ci_crystal_tc[cutoff] = st.bootstrap_pearsonr(y_test, y_pred)\n",
    "    pearsonr_pval_crystal_tc[cutoff] = st.permutation_pearsonr(y_test, y_pred)\n",
    "    y_pred = pd.Series(predicted_docked_tanimoto[cutoff]).loc[pdbbind_test_set]\n",
    "    pearsonr_ci_docked_tc[cutoff] = st.bootstrap_pearsonr(y_test, y_pred)\n",
    "    pearsonr_pval_docked_tc[cutoff] = st.permutation_pearsonr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_features = pd.read_csv('lb_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def get_plec(protein, ligand):\n",
    "    features = PLEC(ligand, protein, depth_ligand=1, depth_protein=5, size=65536, count_bits=True, sparse=True, ignore_hoh=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=8)]: Done 216 out of 216 | elapsed:   39.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=8)]: Done 137 out of 137 | elapsed:   44.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   49.2s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   56.6s\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done 862 out of 862 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=8)]: Done 165 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=8)]: Done 205 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=8)]: Done 226 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=8)]: Done 249 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=8)]: Done 297 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=8)]: Done 322 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=8)]: Done 349 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=8)]: Done 376 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=8)]: Done 405 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=8)]: Done 465 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   59.8s\n",
      "[Parallel(n_jobs=8)]: Done 529 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done 562 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done 597 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 632 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done 669 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done 706 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done 745 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=8)]: Done 825 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done 866 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done 909 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done 952 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=8)]: Done 997 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=8)]: Done 1042 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=8)]: Done 1089 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done 1185 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done 1285 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done 1336 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=8)]: Done 1389 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=8)]: Done 1442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=8)]: Done 1497 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=8)]: Done 1552 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done 1609 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=8)]: Done 1666 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=8)]: Done 1725 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=8)]: Done 1845 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=8)]: Done 1906 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done 1969 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=8)]: Done 2021 out of 2021 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done  61 out of  69 | elapsed:   12.5s remaining:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done  69 out of  69 | elapsed:   13.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=8)]: Done 143 out of 143 | elapsed:   24.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 143 out of 143 | elapsed:   24.5s finished\n"
     ]
    }
   ],
   "source": [
    "targets = ['AKT1', 'CP3A4', 'GCR', 'HIVPR', 'HIVRT', 'KIF11']\n",
    "chembl_plecs = {}\n",
    "for target in targets:\n",
    "    protein = next(ob.readfile('pdb', f'../dude_chembl/dude_data/{target.lower()}/receptor.pdb'))\n",
    "    protein.protein = True\n",
    "    ligands = {}\n",
    "    ligand_file = f'../dude_chembl/{target}_docked.sdf'\n",
    "    for mol in ob.readfile('sdf', ligand_file):\n",
    "        mol_name = mol.OBMol.GetTitle()\n",
    "        if mol_name in ligands:\n",
    "            continue\n",
    "        ligands[mol_name] = mol\n",
    "    with Parallel(n_jobs=8, verbose=10) as parallel:\n",
    "        results = parallel(get_plec(protein, ligands[mol_name]) for mol_name in ligands)\n",
    "    chembl_plecs[target] = {mol_name: result for mol_name, result in zip(ligands, results)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dude_chembl_plec_finterprints.json', 'w') as f:\n",
    "    json.dump(chembl_plecs, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in train_features_crystal], format='csr')\n",
    "X_test_sparse = sparse.vstack([sparse_to_csr_matrix(test_features_crystal[pdb], size=65536) for pdb in test_features_crystal], format='csr')\n",
    "\n",
    "svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_sparse)\n",
    "X_train_svd = svd.transform(X_train_sparse)\n",
    "X_test_svd = svd.transform(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crystal_pose_features = pd.read_csv('../data/crystal_pose_features.csv', index_col=0)\n",
    "feature_sets = {}\n",
    "with open('../data/lb_feature_names.txt') as f:\n",
    "    feature_sets['LB'] = pd.Index([l.strip() for l in f])\n",
    "lb_features = pd.read_csv('../data/crystal_pose_features.csv', index_col=0).loc[:, feature_sets['LB']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_training_set_pk = pd.read_csv('../data/pdbbind_training_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)\n",
    "pdbbind_test_set_pk = pd.read_csv('../data/pdbbind_test_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "40\n",
      "50\n",
      "70\n",
      "90\n",
      "95\n",
      "100\n",
      "All\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "predicted_svd_crystal_sequence_identity = {}\n",
    "predicted_svd_docked_sequence_identity = {}\n",
    "pearsonr_svd_crystal_sequence_identity = {}\n",
    "pearsonr_svd_docked_sequence_identity = {}\n",
    "\n",
    "predicted_svd_rdk_crystal_sequence_identity = {}\n",
    "predicted_svd_rdk_docked_sequence_identity = {}\n",
    "pearsonr_svd_rdk_crystal_sequence_identity = {}\n",
    "pearsonr_svd_rdk_docked_sequence_identity = {}\n",
    "\n",
    "y_test = []\n",
    "for pdb in pdbbind_test_set:\n",
    "    y_test.append(pdbbind_test_set_pk.loc[pdb])\n",
    "\n",
    "for cutoff in test_set_similar_pdbs:\n",
    "    print(cutoff)\n",
    "    y_train = []\n",
    "    X_train_crystal = []\n",
    "    X_train_docked = []\n",
    "    for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, pdbbind_training_set):\n",
    "        if pdb in test_set_similar_pdbs[cutoff]:\n",
    "            continue\n",
    "        X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "        X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "        y_train.append(pdbbind_training_set_pk.loc[pdb])\n",
    "    X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "    X_train_docked = sparse.vstack(X_train_docked, format='csr')\n",
    "    \n",
    "    # need to rebuild test set each time as svd will be different\n",
    "    X_test_crystal = []\n",
    "    X_test_docked = []\n",
    "    for pdb in pdbbind_test_set:\n",
    "        X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "        X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "    X_test_docked = sparse.vstack(X_test_docked, format='csr')\n",
    "\n",
    "    training_set = pdbbind_training_set.difference(test_set_similar_pdbs[cutoff])\n",
    "    rdk_train = lb_features.loc[training_set].values\n",
    "    rdk_test = lb_features.loc[pdbbind_test_set].values\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_crystal)\n",
    "    X_train_crystal = svd.transform(X_train_crystal)\n",
    "    X_test_crystal = svd.transform(X_test_crystal)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_docked)\n",
    "    X_train_docked = svd.transform(X_train_docked)\n",
    "    X_test_docked = svd.transform(X_test_docked)\n",
    "    \n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_svd_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_svd_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_svd_crystal_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_crystal)}\n",
    "    predicted_svd_docked_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_docked)}\n",
    "    \n",
    "    pearsonr_svd_crystal_sequence_identity[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_crystal)\n",
    "    pearsonr_svd_docked_sequence_identity[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_docked)\n",
    "    \n",
    "    # add rdk features\n",
    "    \n",
    "    X_train_crystal = np.concatenate((X_train_crystal, rdk_train), axis=1)\n",
    "    X_test_crystal = np.concatenate((X_test_crystal, rdk_test), axis=1)\n",
    "    X_train_docked = np.concatenate((X_train_docked, rdk_train), axis=1)\n",
    "    X_test_docked = np.concatenate((X_test_docked, rdk_test), axis=1)\n",
    "\n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_svd_rdk_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_svd_rdk_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_svd_rdk_crystal_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_rdk_crystal)}\n",
    "    predicted_svd_rdk_docked_sequence_identity[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_rdk_docked)}\n",
    "    \n",
    "    pearsonr_svd_rdk_crystal_sequence_identity[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_rdk_crystal)\n",
    "    pearsonr_svd_rdk_docked_sequence_identity[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_rdk_docked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.0\n",
      "All\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "predicted_svd_crystal_tanimoto = {}\n",
    "predicted_svd_docked_tanimoto = {}\n",
    "pearsonr_svd_crystal_tanimoto = {}\n",
    "pearsonr_svd_docked_tanimoto = {}\n",
    "\n",
    "predicted_svd_rdk_crystal_tanimoto = {}\n",
    "predicted_svd_rdk_docked_tanimoto = {}\n",
    "pearsonr_svd_rdk_crystal_tanimoto = {}\n",
    "pearsonr_svd_rdk_docked_tanimoto = {}\n",
    "\n",
    "y_test = []\n",
    "for pdb in pdbbind_test_set:\n",
    "    y_test.append(pdbbind_test_set_pk.loc[pdb])\n",
    "\n",
    "for cutoff in test_set_similar_ligands:\n",
    "    print(cutoff)\n",
    "    y_train = []\n",
    "    X_train_crystal = []\n",
    "    X_train_docked = []\n",
    "    for plec_docked, plec_crystal, pdb in zip(train_features_crystal, train_features_docked, pdbbind_training_set):\n",
    "        if pdb in test_set_similar_ligands[cutoff]:\n",
    "            continue\n",
    "        X_train_crystal.append(sparse_to_csr_matrix(plec_crystal, size=65536))\n",
    "        X_train_docked.append(sparse_to_csr_matrix(plec_docked, size=65536))\n",
    "        y_train.append(pdbbind_training_set_pk.loc[pdb])\n",
    "    X_train_crystal = sparse.vstack(X_train_crystal, format='csr')\n",
    "    X_train_docked = sparse.vstack(X_train_docked, format='csr')\n",
    "    \n",
    "    # need to rebuild test set each time as svd will be different\n",
    "    X_test_crystal = []\n",
    "    X_test_docked = []\n",
    "    for pdb in pdbbind_test_set:\n",
    "        X_test_crystal.append(sparse_to_csr_matrix(test_features_crystal[pdb], size=65536))\n",
    "        X_test_docked.append(sparse_to_csr_matrix(test_features_docked[pdb], size=65536))\n",
    "    X_test_crystal = sparse.vstack(X_test_crystal, format='csr')\n",
    "    X_test_docked = sparse.vstack(X_test_docked, format='csr')\n",
    "\n",
    "    training_set = pdbbind_training_set.difference(test_set_similar_ligands[cutoff])\n",
    "    rdk_train = lb_features.loc[training_set].values\n",
    "    rdk_test = lb_features.loc[pdbbind_test_set].values\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_crystal)\n",
    "    X_train_crystal = svd.transform(X_train_crystal)\n",
    "    X_test_crystal = svd.transform(X_test_crystal)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train_docked)\n",
    "    X_train_docked = svd.transform(X_train_docked)\n",
    "    X_test_docked = svd.transform(X_test_docked)\n",
    "    \n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_svd_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_svd_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_svd_crystal_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_crystal)}\n",
    "    predicted_svd_docked_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_docked)}\n",
    "    \n",
    "    pearsonr_svd_crystal_tanimoto[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_crystal)\n",
    "    pearsonr_svd_docked_tanimoto[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_docked)\n",
    "    \n",
    "    # add rdk features\n",
    "    \n",
    "    X_train_crystal = np.concatenate((X_train_crystal, rdk_train), axis=1)\n",
    "    X_test_crystal = np.concatenate((X_test_crystal, rdk_test), axis=1)\n",
    "    X_train_docked = np.concatenate((X_train_docked, rdk_train), axis=1)\n",
    "    X_test_docked = np.concatenate((X_test_docked, rdk_test), axis=1)\n",
    "\n",
    "    rf_crystal = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_crystal.fit(X_train_crystal, y_train)\n",
    "    rf_docked = RandomForestRegressor(n_estimators=500, max_features=0.33,random_state=42, n_jobs=8, oob_score=True)\n",
    "    rf_docked.fit(X_train_docked, y_train)\n",
    "    \n",
    "    predicted_svd_rdk_crystal = rf_crystal.predict(X_test_crystal)\n",
    "    predicted_svd_rdk_docked = rf_docked.predict(X_test_docked)\n",
    "    predicted_svd_rdk_crystal_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_rdk_crystal)}\n",
    "    predicted_svd_rdk_docked_tanimoto[cutoff] = {pdb: pred for pdb, pred in zip(pdbbind_test_set, predicted_svd_rdk_docked)}\n",
    "    \n",
    "    pearsonr_svd_rdk_crystal_tanimoto[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_rdk_crystal)\n",
    "    pearsonr_svd_rdk_docked_tanimoto[cutoff] = bootstrap_pearsonr(np.array(y_test), predicted_svd_rdk_docked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
