{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdbbind_training_set_pk = pd.read_csv('../data/pdbbind_training_set_binding_affinity.csv', index_col=0, header=None, squeeze=True)\n",
    "\n",
    "crystal_pose_features = pd.read_csv('../data/crystal_pose_features.csv', index_col=0)\n",
    "minimised_pose_features = pd.read_csv('../data/minimised_pose_features.csv', index_col=0)\n",
    "docked_pose_features = pd.read_csv('../data/docked_pose_features.csv', index_col=0)\n",
    "\n",
    "feature_sets = {}\n",
    "with open('../data/lb_feature_names.txt') as f:\n",
    "    feature_sets['LB'] = pd.Index([l.strip() for l in f])\n",
    "with open('../data/sb_feature_names.txt') as f:\n",
    "    feature_sets['SB'] = pd.Index([l.strip() for l in f])\n",
    "with open('../data/hb_feature_names.txt') as f:\n",
    "    feature_sets['HB'] = pd.Index([l.strip() for l in f])\n",
    "\n",
    "# We've enumerated the docked poses associated to each PDB structure - these labels are used for cross-validation later\n",
    "with open('../data/docked_pose_labels.json') as f:\n",
    "    docked_pose_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare cross-validation folds\n",
    "\n",
    "Randomly shuffle and split into five folds - we'll use the same folds across all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = pdbbind_training_set_pk.sample(frac=1, replace=False, random_state=42).index\n",
    "n_test = int(len(shuffled) / 5)\n",
    "folds = [shuffled[:n_test], shuffled[n_test:2*n_test], shuffled[2*n_test:3*n_test], shuffled[3*n_test:4*n_test], shuffled[4*n_test:]]\n",
    "\n",
    "pdbbind_training_set = pdbbind_training_set_pk.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of Vina scoring function on CV folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vina_crystal_pk = pd.read_csv('../results/vina_crystal_predicted_pk.csv', index_col=0, squeeze=True)\n",
    "vina_docked_pk = pd.read_csv('../results/vina_docked_predicted_pk.csv', index_col=0, squeeze=True)\n",
    "vina_docked_mean_pk = pd.read_csv('../results/vina_docked_mean_predicted_pk.csv', index_col=0, squeeze=True)\n",
    "vina_minimized_pk = pd.read_csv('../results/vina_minimized_predicted_pk.csv', index_col=0, squeeze=True)\n",
    "\n",
    "vina_crystal_fold_pearsonr = []\n",
    "vina_docked_fold_pearsonr = []\n",
    "vina_mean_docked_fold_pearsonr = []\n",
    "vina_minimized_fold_pearsonr = []\n",
    "\n",
    "for fold in folds:\n",
    "    y_true = pdbbind_training_set_pk.loc[fold]\n",
    "    # crystal\n",
    "    y_pred = vina_crystal_pk.loc[fold]\n",
    "    vina_crystal_fold_pearsonr.append(stats.pearsonr(y_true, y_pred)[0])\n",
    "    # docked\n",
    "    y_pred = vina_docked_pk.loc[fold]\n",
    "    vina_docked_fold_pearsonr.append(stats.pearsonr(y_true, y_pred)[0])\n",
    "    # docked (mean)\n",
    "    y_pred = vina_docked_mean_pk.loc[fold]\n",
    "    vina_mean_docked_fold_pearsonr.append(stats.pearsonr(y_true, y_pred)[0])\n",
    "    # minimized\n",
    "    y_pred = vina_minimized_pk.loc[fold]\n",
    "    vina_minimized_fold_pearsonr.append(stats.pearsonr(y_true, y_pred)[0])\n",
    "vina_crystal_cv_pearsonr = np.mean(vina_crystal_fold_pearsonr)\n",
    "vina_docked_cv_pearsonr = np.mean(vina_docked_fold_pearsonr)\n",
    "vina_mean_docked_cv_pearsonr = np.mean(vina_mean_docked_fold_pearsonr)\n",
    "vina_minimized_cv_pearsonr = np.mean(vina_minimized_fold_pearsonr)\n",
    "vina_crystal_cv_pearsonr_stdev = np.std(vina_crystal_fold_pearsonr)\n",
    "vina_docked_cv_pearsonr_stdev = np.std(vina_docked_fold_pearsonr)\n",
    "vina_mean_docked_cv_pearsonr_stdev = np.std(vina_mean_docked_fold_pearsonr)\n",
    "vina_minimized_cv_pearsonr_stdev = np.std(vina_minimized_fold_pearsonr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vina_crystal_cv_pearsonr, vina_crystal_cv_pearsonr_stdev)\n",
    "print(vina_docked_cv_pearsonr, vina_docked_cv_pearsonr_stdev)\n",
    "print(vina_mean_docked_cv_pearsonr, vina_mean_docked_cv_pearsonr_stdev)\n",
    "print(vina_minimized_cv_pearsonr, vina_minimized_cv_pearsonr_stdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation using crystal poses\n",
    "\n",
    "For reference, we first establish a benchmark by performing the cross-validation experiment using crystal poses for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_crystal_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr = []\n",
    "    fold_mse = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        X_train = crystal_pose_features.loc[index_train, feature_sets[model]].values\n",
    "        X_test = crystal_pose_features.loc[fold, feature_sets[model]].values\n",
    "        y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        pred = rf.predict(X_test)\n",
    "        fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "        fold_mse.append(mean_squared_error(y_test, pred))\n",
    "    cv_crystal_results[model] = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}\n",
    "\n",
    "with open('../results/cv_crystal_results.json', 'w') as f:\n",
    "    json.dump(cv_crystal_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_minimised_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr = []\n",
    "    fold_mse = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        X_train = minimised_pose_features.loc[index_train, feature_sets[model]].values\n",
    "        X_test = minimised_pose_features.loc[fold, feature_sets[model]].values\n",
    "        y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        pred = rf.predict(X_test)\n",
    "        fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "        fold_mse.append(mean_squared_error(y_test, pred))\n",
    "    cv_minimised_results[model] = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}\n",
    "\n",
    "with open('../results/cv_minimised_results.json', 'w') as f:\n",
    "    json.dump(cv_minimised_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation using minimised poses\n",
    "\n",
    "We repeat the benchmarking exercise, this time using minimized poses of each ligand for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oddt.fingerprints import sparse_to_csr_matrix, csr_matrix_to_sparse, fold, sparse_to_dense\n",
    "from scipy import sparse\n",
    "\n",
    "with open('../data/pdbbind_training_set.txt') as f:\n",
    "    train_pdbs = [l.strip() for l in f]\n",
    "\n",
    "with open('pdbbind_training_set_docked_plec_sparse.json') as f:\n",
    "    train_features_docked = json.load(f)\n",
    "    \n",
    "plec_docked = {pdb: feats for pdb, feats in zip(train_pdbs, train_features_docked)}\n",
    "    \n",
    "with open('pdbbind_training_set_crystal_plec_sparse.json') as f:\n",
    "    train_features_crystal = json.load(f)\n",
    "    \n",
    "plec_crystal = {pdb: feats for pdb, feats in zip(train_pdbs, train_features_crystal)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLECscore\n",
    "\n",
    "using original parameters i.e. 100 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plecscore_crystal_fold_predicted = []\n",
    "plecscore_docked_fold_predicted = []\n",
    "plecscore_fold_crystal_pearsonr = []\n",
    "plecscore_fold_docked_pearsonr = []\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'Fold {i+1}')\n",
    "    fold_train = pdbbind_training_set.difference(fold)\n",
    "    y_train = pdbbind_training_set_pk.loc[fold_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    training_features = [plec_crystal[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_crystal[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=6)\n",
    "    print('Crystal')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plecscore_fold_crystal_pearsonr.append(rp)\n",
    "    plecscore_crystal_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})\n",
    "    \n",
    "    training_features = [plec_docked[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_docked[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=6)\n",
    "    print('Docked')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plecscore_fold_docked_pearsonr.append(rp)\n",
    "    plecscore_docked_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plec_crystal_fold_predicted = []\n",
    "plec_docked_fold_predicted = []\n",
    "plec_fold_crystal_pearsonr = []\n",
    "plec_fold_docked_pearsonr = []\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'Fold {i+1}')\n",
    "    fold_train = pdbbind_training_set.difference(fold)\n",
    "    y_train = pdbbind_training_set_pk.loc[fold_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    training_features = [plec_crystal[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_crystal[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=6)\n",
    "    print('Crystal')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_fold_crystal_pearsonr.append(rp)\n",
    "    plec_crystal_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})\n",
    "    \n",
    "    training_features = [plec_docked[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_docked[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=6)\n",
    "    print('Docked')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_fold_docked_pearsonr.append(rp)\n",
    "    plec_docked_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLEC with Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plec_svd_crystal_fold_predicted = []\n",
    "plec_svd_docked_fold_predicted = []\n",
    "plec_svd_fold_crystal_pearsonr = []\n",
    "plec_svd_fold_docked_pearsonr = []\n",
    "plec_svd_rdk_crystal_fold_predicted = []\n",
    "plec_svd_rdk_docked_fold_predicted = []\n",
    "plec_svd_rdk_fold_crystal_pearsonr = []\n",
    "plec_svd_rdk_fold_docked_pearsonr = []\n",
    "\n",
    "lb_features = crystal_pose_features.loc[pdbbind_training_set, feature_sets['LB']]\n",
    "#rfv2_rdk_features_crystal = pd.concat([rfv2_features_crystal, lb_features], axis='columns')\n",
    "#rfv2_rdk_features_docked = pd.concat([rfv2_features_docked, lb_features], axis='columns')\n",
    "\n",
    "\n",
    "for i, fold in enumerate(folds):\n",
    "    print(f'Fold {i+1}')\n",
    "    fold_train = pdbbind_training_set.difference(fold)\n",
    "    \n",
    "    # lb features\n",
    "    rdk_train = lb_features.loc[fold_train].values\n",
    "    rdk_test = lb_features.loc[fold].values\n",
    "    \n",
    "    y_train = pdbbind_training_set_pk.loc[fold_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    training_features = [plec_crystal[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_crystal[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train)\n",
    "    X_train = svd.transform(X_train)\n",
    "    X_test = svd.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=8, max_features=0.33)\n",
    "    print('Crystal')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_svd_fold_crystal_pearsonr.append(rp)\n",
    "    plec_svd_crystal_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})\n",
    "    \n",
    "    # add lb features\n",
    "    X_train_rdk = np.concatenate((X_train, rdk_train), axis=1)\n",
    "    X_test_rdk = np.concatenate((X_test, rdk_test), axis=1)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=8, max_features=0.33)\n",
    "    rf.fit(X_train_rdk, y_train)\n",
    "    pred = rf.predict(X_test_rdk)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_svd_rdk_fold_crystal_pearsonr.append(rp)\n",
    "    plec_svd_rdk_crystal_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})\n",
    "\n",
    "    training_features = [plec_docked[pdb] for pdb in fold_train]\n",
    "    test_features = [plec_docked[pdb] for pdb in fold]\n",
    "    X_train = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in training_features], format='csr')\n",
    "    X_test = sparse.vstack([sparse_to_csr_matrix(plec, size=65536) for plec in test_features], format='csr')\n",
    "    svd = TruncatedSVD(n_components=200, random_state=42).fit(X_train)\n",
    "    X_train = svd.transform(X_train)\n",
    "    X_test = svd.transform(X_test)\n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=8)\n",
    "    print('Docked')\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_svd_fold_docked_pearsonr.append(rp)\n",
    "    plec_svd_docked_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})\n",
    "    \n",
    "    # add lb features\n",
    "    X_train_rdk = np.concatenate((X_train, rdk_train), axis=1)\n",
    "    X_test_rdk = np.concatenate((X_test, rdk_test), axis=1)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=500, random_state=42, n_jobs=8, max_features=0.33)\n",
    "    rf.fit(X_train_rdk, y_train)\n",
    "    pred = rf.predict(X_test_rdk)\n",
    "    rp = stats.pearsonr(y_test, pred)[0]\n",
    "    plec_svd_rdk_fold_docked_pearsonr.append(rp)\n",
    "    plec_svd_rdk_docked_fold_predicted.append({pdb: score for pdb, score in zip(fold, pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/cross_validation_plec_crystal_predictions.json', 'w') as f:\n",
    "    json.dump(plec_crystal_fold_predicted, f, cls=NumpyEncoder)\n",
    "    \n",
    "with open('../results/cross_validation_plec_docked_predictions.json', 'w') as f:\n",
    "    json.dump(plec_docked_fold_predicted, f, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_fold_crystal_pearsonr = []\n",
    "for plec_fold in plec_crystal_fold_predicted:\n",
    "    pred = pd.Series(plec_fold)\n",
    "    y_true = pdbbind_training_set_pk.loc[pred.index]\n",
    "    plec_fold_crystal_pearsonr.append(stats.pearsonr(y_true, pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plec_fold_docked_pearsonr = []\n",
    "for plec_fold in plec_docked_fold_predicted:\n",
    "    pred = pd.Series(plec_fold)\n",
    "    y_true = pdbbind_training_set_pk.loc[pred.index]\n",
    "    plec_fold_docked_pearsonr.append(stats.pearsonr(y_true, pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_fold_docked_predicted = []\n",
    "\n",
    "for fold in folds:\n",
    "    index_train = pdbbind_training_set.difference(fold)\n",
    "\n",
    "    X_train = lb_features.loc[index_train].values\n",
    "    y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    X_test = lb_features.loc[fold].values\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "    pred = pd.Series(data=rf.predict(X_test), index=fold)\n",
    "    lb_fold_docked_predicted.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_rps = []\n",
    "for plec_fold, lb_fold in zip(plec_docked_fold_predicted, lb_fold_docked_predicted):\n",
    "    pred = pd.Series(plec_fold).loc[lb_fold.index]\n",
    "    stacked_pred = pd.Series({pdb: (pred[pdb] + lb_fold[pdb])/2 for pdb in pred.index})\n",
    "    y_true = pdbbind_training_set_pk.loc[pred.index]\n",
    "    fold_rps.append(stats.pearsonr(y_true, stacked_pred)[0])\n",
    "np.mean(fold_rps), np.std(fold_rps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_rps = []\n",
    "for plec_fold, lb_fold in zip(plec_crystal_fold_predicted, lb_fold_docked_predicted):\n",
    "    pred = pd.Series(plec_fold).loc[lb_fold.index]\n",
    "    stacked_pred = pd.Series({pdb: (pred[pdb] + lb_fold[pdb])/2 for pdb in pred.index})\n",
    "    y_true = pdbbind_training_set_pk.loc[pred.index]\n",
    "    fold_rps.append(stats.pearsonr(y_true, stacked_pred)[0])\n",
    "np.mean(fold_rps), np.std(fold_rps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_docked_results = {}\n",
    "\n",
    "for model in ['SB' ,'LB']\n",
    "    fold_results = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        training_pose_labels = []\n",
    "\n",
    "        # Get the labels for the highest-ranked pose for each training complex\n",
    "        for pdb in index_train:\n",
    "            training_pose_labels.append(docked_pose_labels[pdb][0])\n",
    "        training_pose_labels = pd.Index(training_pose_labels)\n",
    "\n",
    "        X_train = docked_pose_features.loc[training_pose_labels, feature_sets[model]].values\n",
    "        y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # List docked poses for this fold\n",
    "        fold_dock_labels = []\n",
    "        for pdb in fold:\n",
    "            fold_dock_labels.extend(docked_pose_labels[pdb])\n",
    "        fold_dock_labels = pd.Index(fold_dock_labels)\n",
    "\n",
    "        X_test = docked_pose_features.loc[fold_dock_labels, feature_sets[model]].values\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "        pred = pd.Series(data=rf.predict(X_test), index=fold_dock_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - scoring strategy\n",
    "\n",
    "First we run the cross-validation experiment using different strategies for scoring a ligand when multiple docked poses are available. Three strategies were tested: scoring the pose ranked highest by Smina (\"top dock\"); scoring all poses and taxing the highest score (\"all docks max\"); and scoring all poses and taking the mean score (\"all docks mean\"). Models are trained using a single pose for each ligand, minimised using Smina to achieve a single near-native docked pose. We also train and test using crystal poses for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_minimized_test_top_dock_results = {}\n",
    "cv_train_minimized_test_all_docks_max_results = {}\n",
    "cv_train_minimized_test_all_docks_mean_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr_max = []\n",
    "    fold_pearsonr_mean = []\n",
    "    fold_pearsonr_top = []\n",
    "    fold_mse_max = []\n",
    "    fold_mse_mean = []\n",
    "    fold_mse_top = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        X_train = minimised_pose_features.loc[index_train, feature_sets[model]].values\n",
    "        y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # List docked poses for this fold\n",
    "        fold_dock_labels = []\n",
    "        for pdb in fold:\n",
    "            fold_dock_labels.extend(docked_pose_labels[pdb])\n",
    "        fold_dock_labels = pd.Index(fold_dock_labels)\n",
    "\n",
    "        X_test = docked_pose_features.loc[fold_dock_labels, feature_sets[model]].values\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "        pred = pd.Series(data=rf.predict(X_test), index=fold_dock_labels)\n",
    "\n",
    "        # Score all poses, taking max/mean score for each ligand\n",
    "        max_pred = []\n",
    "        mean_pred = []\n",
    "\n",
    "        for pdb in fold:\n",
    "            max_pred.append(np.max(pred.loc[docked_pose_labels[pdb]]))\n",
    "            mean_pred.append(np.mean(pred.loc[docked_pose_labels[pdb]]))\n",
    "        fold_pearsonr_max.append(stats.pearsonr(y_test, max_pred)[0])\n",
    "        fold_pearsonr_mean.append(stats.pearsonr(y_test, mean_pred)[0])\n",
    "        fold_mse_max.append(mean_squared_error(y_test, max_pred))\n",
    "        fold_mse_mean.append(mean_squared_error(y_test, mean_pred))\n",
    "\n",
    "        # Take the score of the pose ranked highest by Smina\n",
    "        top_pred = []\n",
    "        for pdb in fold:\n",
    "            top_pred.append(pred.loc[docked_pose_labels[pdb][0]])\n",
    "        fold_pearsonr_top.append(stats.pearsonr(y_test, top_pred)[0])\n",
    "        fold_mse_top.append(mean_squared_error(y_test, top_pred))\n",
    "    \n",
    "    cv_train_minimized_test_all_docks_max_results[model] = {'pearsonr': np.mean(fold_pearsonr_max), \n",
    "                                                            'pearsonr_stdev': np.std(fold_pearsonr_max), \n",
    "                                                            'rmse': np.sqrt(np.mean(fold_mse_max))}\n",
    "    \n",
    "    cv_train_minimized_test_all_docks_mean_results[model] = {'pearsonr': np.mean(fold_pearsonr_mean), \n",
    "                                                             'pearsonr_stdev': np.std(fold_pearsonr_mean),\n",
    "                                                             'rmse': np.sqrt(np.mean(fold_mse_mean))}\n",
    "    cv_train_minimized_test_top_dock_results[model] = {'pearsonr': np.mean(fold_pearsonr_top), \n",
    "                                                       'pearsonr_stdev': np.std(fold_pearsonr_top),\n",
    "                                                       'rmse': np.sqrt(np.mean(fold_mse_top))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy_pearsonr = {\n",
    "    'Smina top pose': {model: cv_train_minimized_test_top_dock_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Maximum pose score': {model: cv_train_minimized_test_all_docks_max_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Mean pose score': {model: cv_train_minimized_test_all_docks_mean_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Train-test crystal': {m: cv_crystal_results[m]['pearsonr'] for m in feature_sets}\n",
    "}\n",
    "test_strategy_pearsonr = pd.DataFrame(test_strategy_pearsonr).loc[['LB','SB','HB']]\n",
    "test_strategy_pearsonr.index = ['LB model', 'SB model','HB model']\n",
    "test_strategy_pearsonr.T.to_csv('../results/train_minimised_pose_cv_pearsonr.csv')\n",
    "test_strategy_pearsonr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy_pearsonr_stdev = {\n",
    "    'Smina top pose': {model: cv_train_minimized_test_top_dock_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Maximum pose score': {model: cv_train_minimized_test_all_docks_max_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Mean pose score': {model: cv_train_minimized_test_all_docks_mean_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Train-test crystal': {m: cv_crystal_results[m]['pearsonr_stdev'] for m in feature_sets}\n",
    "}\n",
    "test_strategy_pearsonr_stdev = pd.DataFrame(test_strategy_pearsonr_stdev).loc[['LB','SB','HB']]\n",
    "test_strategy_pearsonr_stdev.index = ['LB model', 'SB model','HB model']\n",
    "test_strategy_pearsonr_stdev.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Training on docked poses\n",
    "\n",
    "Next, we repeat the cross-validation experiment, this itme training on the docked pose ranked highest by Smina for each ligand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_top_dock_test_top_dock_results = {}\n",
    "cv_train_top_dock_test_all_docks_max_results = {}\n",
    "cv_train_top_dock_test_all_docks_mean_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr_max = []\n",
    "    fold_pearsonr_mean = []\n",
    "    fold_pearsonr_top = []\n",
    "    fold_mse_max = []\n",
    "    fold_mse_mean = []\n",
    "    fold_mse_top = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        training_pose_labels = []\n",
    "\n",
    "        # Get the labels for the highest-ranked pose for each training complex\n",
    "        for pdb in index_train:\n",
    "            training_pose_labels.append(docked_pose_labels[pdb][0])\n",
    "        training_pose_labels = pd.Index(training_pose_labels)\n",
    "\n",
    "        X_train = docked_pose_features.loc[training_pose_labels, feature_sets[model]].values\n",
    "        y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # List docked poses for this fold\n",
    "        fold_dock_labels = []\n",
    "        for pdb in fold:\n",
    "            fold_dock_labels.extend(docked_pose_labels[pdb])\n",
    "        fold_dock_labels = pd.Index(fold_dock_labels)\n",
    "\n",
    "        X_test = docked_pose_features.loc[fold_dock_labels, feature_sets[model]].values\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "        pred = pd.Series(data=rf.predict(X_test), index=fold_dock_labels)\n",
    "\n",
    "        # Score all poses, taking max/mean score for each ligand\n",
    "        max_pred = []\n",
    "        mean_pred = []\n",
    "\n",
    "        for pdb in fold:\n",
    "            max_pred.append(np.max(pred.loc[docked_pose_labels[pdb]]))\n",
    "            mean_pred.append(np.mean(pred.loc[docked_pose_labels[pdb]]))\n",
    "        fold_pearsonr_max.append(stats.pearsonr(y_test, max_pred)[0])\n",
    "        fold_pearsonr_mean.append(stats.pearsonr(y_test, mean_pred)[0])\n",
    "        fold_mse_max.append(mean_squared_error(y_test, max_pred))\n",
    "        fold_mse_mean.append(mean_squared_error(y_test, mean_pred))\n",
    "\n",
    "        # Take the score of the pose ranked highest by Smina\n",
    "        top_pred = []\n",
    "        for pdb in fold:\n",
    "            top_pred.append(pred.loc[docked_pose_labels[pdb][0]])\n",
    "        fold_pearsonr_top.append(stats.pearsonr(y_test, top_pred)[0])\n",
    "        fold_mse_top.append(mean_squared_error(y_test, top_pred))\n",
    "\n",
    "    cv_train_top_dock_test_all_docks_max_results[model] = {'pearsonr': np.mean(fold_pearsonr_max), \n",
    "                                                            'pearsonr_stdev': np.std(fold_pearsonr_max), \n",
    "                                                            'rmse': np.sqrt(np.mean(fold_mse_max))}\n",
    "    \n",
    "    cv_train_top_dock_test_all_docks_mean_results[model] = {'pearsonr': np.mean(fold_pearsonr_mean), \n",
    "                                                            'pearsonr_stdev': np.std(fold_pearsonr_mean), \n",
    "                                                            'rmse': np.sqrt(np.mean(fold_mse_mean))}\n",
    "    cv_train_top_dock_test_top_dock_results[model] = {'pearsonr': np.mean(fold_pearsonr_top), \n",
    "                                                      'pearsonr_stdev': np.std(fold_pearsonr_top), \n",
    "                                                      'rmse': np.sqrt(np.mean(fold_mse_top))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy_pearsonr = {\n",
    "    'Smina top pose': {model: cv_train_top_dock_test_top_dock_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Maximum pose score': {model: cv_train_top_dock_test_all_docks_max_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Mean pose score': {model: cv_train_top_dock_test_all_docks_mean_results[model]['pearsonr'] for model in feature_sets},\n",
    "    'Train-test crystal': {m: cv_crystal_results[m]['pearsonr'] for m in feature_sets}\n",
    "}\n",
    "test_strategy_pearsonr = pd.DataFrame(test_strategy_pearsonr).loc[['LB','SB','HB']]\n",
    "test_strategy_pearsonr.index = ['LB model', 'SB model','HB model']\n",
    "test_strategy_pearsonr.T.to_csv('../results/train_top_docked_pose_cv_pearsonr.csv')\n",
    "test_strategy_pearsonr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strategy_pearsonr_stdev = {\n",
    "    'Smina top pose': {model: cv_train_top_dock_test_top_dock_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Maximum pose score': {model: cv_train_top_dock_test_all_docks_max_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Mean pose score': {model: cv_train_top_dock_test_all_docks_mean_results[model]['pearsonr_stdev'] for model in feature_sets},\n",
    "    'Train-test crystal': {m: cv_crystal_results[m]['pearsonr_stdev'] for m in feature_sets}\n",
    "}\n",
    "test_strategy_pearsonr_stdev = pd.DataFrame(test_strategy_pearsonr_stdev).loc[['LB','SB','HB']]\n",
    "test_strategy_pearsonr_stdev.index = ['LB model', 'SB model','HB model']\n",
    "test_strategy_pearsonr_stdev.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Training using multiple poses\n",
    "\n",
    "Next we again repeat the cross-validation experiment, this time training on all of the docked poses for each ligand. To control for the effect of increasing the size of training set, we also repeat the experiment by training on a number of redundant copies of the top pose for each ligand equal to the number of docked poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run cv on docks, training on all docks\n",
    "cv_train_all_docks_test_all_docks_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr = []\n",
    "    fold_mse = []\n",
    "    for fold in folds:\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        \n",
    "        training_pose_labels = []\n",
    "        for pdb in index_train:\n",
    "            training_pose_labels.extend(docked_pose_labels[pdb])\n",
    "        training_pose_labels = pd.Index(training_pose_labels)\n",
    "\n",
    "        X_train = docked_pose_features.loc[training_pose_labels, feature_sets[model]].values\n",
    "        # Training affinities are the same for each pose of a ligand\n",
    "        training_pose_pdbs = pd.Index(i[:4] for i in training_pose_labels)\n",
    "        y_train = pdbbind_training_set_pk.loc[training_pose_pdbs].values.ravel()\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # test on all docks\n",
    "        fold_pose_labels = []\n",
    "        for pdb in fold:\n",
    "            fold_pose_labels.extend(docked_pose_labels[pdb])\n",
    "        fold_pose_labels = pd.Index(fold_pose_labels)\n",
    "        X_test = docked_pose_features.loc[fold_pose_labels, feature_sets[model]].values\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "        pred = pd.Series(data=rf.predict(X_test), index=fold_pose_labels)\n",
    "        max_pred = []\n",
    "        for pdb in fold:\n",
    "            max_pred.append(np.max(pred.loc[docked_pose_labels[pdb]]))\n",
    "        fold_pearsonr.append(stats.pearsonr(y_test, max_pred)[0])\n",
    "        fold_mse.append(mean_squared_error(y_test, max_pred))\n",
    "\n",
    "    cv_train_all_docks_test_all_docks_results[model] = {'pearsonr': np.mean(fold_pearsonr), \n",
    "                                                        'rmse': np.sqrt(np.mean(fold_mse)), \n",
    "                                                        'pearsonr_stdev': np.std(fold_pearsonr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_redundant_docks_test_all_docks_results = {}\n",
    "\n",
    "for model in feature_sets:\n",
    "    fold_pearsonr = []\n",
    "    fold_mse = []\n",
    "    for fold in folds:\n",
    "\n",
    "        index_train = pdbbind_training_set.difference(fold)\n",
    "        \n",
    "        training_pose_labels = []\n",
    "        for pdb in index_train:\n",
    "            training_pose_labels.extend(docked_pose_labels[pdb])\n",
    "        training_pose_labels = pd.Index(training_pose_labels)\n",
    "\n",
    "        # This time we want N copies of the pose ranked highest by Smina\n",
    "        training_pose_labels = training_pose_labels.map(lambda x: x[:4]+'_0')\n",
    "        X_train = docked_pose_features.loc[training_pose_labels, feature_sets[model]].values\n",
    "\n",
    "        # Training affinities are the same for each pose of a ligand\n",
    "        training_pose_pdbs = pd.Index(i[:4] for i in training_pose_labels)\n",
    "        y_train = pdbbind_training_set_pk.loc[training_pose_pdbs].values.ravel()\n",
    "\n",
    "        rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # test on all docks\n",
    "        fold_pose_labels = []\n",
    "        for pdb in fold:\n",
    "            fold_pose_labels.extend(docked_pose_labels[pdb])\n",
    "        fold_pose_labels = pd.Index(fold_pose_labels)\n",
    "        X_test = docked_pose_features.loc[fold_pose_labels, feature_sets[model]].values\n",
    "        y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "\n",
    "        pred = pd.Series(data=rf.predict(X_test), index=fold_pose_labels)\n",
    "        max_pred = []\n",
    "        for pdb in fold:\n",
    "            max_pred.append(np.max(pred.loc[docked_pose_labels[pdb]]))\n",
    "        fold_pearsonr.append(stats.pearsonr(y_test, max_pred)[0])\n",
    "        fold_mse.append(mean_squared_error(y_test, max_pred))\n",
    "    \n",
    "    cv_train_redundant_docks_test_all_docks_results[model] = {'pearsonr': np.mean(fold_pearsonr), \n",
    "                                                              'rmse': np.sqrt(np.mean(fold_mse)),\n",
    "                                                              'pearsonr_stdev': np.std(fold_pearsonr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipose_pearsonr = {}\n",
    "\n",
    "for m in feature_sets:\n",
    "    multipose_pearsonr[m] = {'Smina top pose': cv_train_top_dock_test_all_docks_max_results[m]['pearsonr'],\n",
    "                                'All poses': cv_train_all_docks_test_all_docks_results[m]['pearsonr'],\n",
    "                                'Redundant poses': cv_train_redundant_docks_test_all_docks_results[m]['pearsonr']}\n",
    "\n",
    "multipose_pearsonr = pd.DataFrame(multipose_pearsonr)[['LB', 'SB', 'HB']]\n",
    "multipose_pearsonr.columns = ['LB model', 'SB model','HB model']\n",
    "multipose_pearsonr.to_csv('../results/train_multiple_poses_cv_pearsonr.csv')\n",
    "multipose_pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipose_pearsonr_stdev = {}\n",
    "\n",
    "for m in feature_sets:\n",
    "    multipose_pearsonr_stdev[m] = {'Smina top pose': cv_train_top_dock_test_all_docks_max_results[m]['pearsonr_stdev'],\n",
    "                                'All poses': cv_train_all_docks_test_all_docks_results[m]['pearsonr_stdev'],\n",
    "                                'Redundant poses': cv_train_redundant_docks_test_all_docks_results[m]['pearsonr_stdev']}\n",
    "\n",
    "multipose_pearsonr_stdev = pd.DataFrame(multipose_pearsonr_stdev)[['LB', 'SB', 'HB']]\n",
    "multipose_pearsonr_stdev.columns = ['LB model', 'SB model','HB model']\n",
    "multipose_pearsonr_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pdbbind_training_set_crystal_rfv2.json') as f:\n",
    "    rfv2_features_crystal = pd.DataFrame(json.load(f)).T\n",
    "with open('pdbbind_training_set_docked_rfv2.json') as f:\n",
    "    rfv2_features_docked = pd.DataFrame(json.load(f)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF-Score v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lb_features = crystal_pose_features.loc[pdbbind_training_set, feature_sets['LB']]\n",
    "rfv2_rdk_features_crystal = pd.concat([rfv2_features_crystal, lb_features], axis='columns')\n",
    "rfv2_rdk_features_docked = pd.concat([rfv2_features_docked, lb_features], axis='columns')\n",
    "\n",
    "rfv2_cv_crystal_results = {}\n",
    "rfv2_cv_docked_results = {}\n",
    "rfv2_rdk_cv_crystal_results = {}\n",
    "rfv2_rdk_cv_docked_results = {}\n",
    "\n",
    "print('RFv2 crytsal')\n",
    "fold_pearsonr = []\n",
    "fold_mse = []\n",
    "for fold in folds:\n",
    "    index_train = pdbbind_training_set.difference(fold)\n",
    "    X_train = rfv2_features_crystal.loc[index_train].values\n",
    "    X_test = rfv2_features_crystal.loc[fold].values\n",
    "    y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_features=14, n_jobs=6, random_state=42) #mtry=14 for rfv2\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "    fold_mse.append(mean_squared_error(y_test, pred))\n",
    "rfv2_cv_crystal_results = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}\n",
    "\n",
    "print('RFv2 docked')\n",
    "fold_pearsonr = []\n",
    "fold_mse = []\n",
    "for fold in folds:\n",
    "    index_train = pdbbind_training_set.difference(fold)\n",
    "    X_train = rfv2_features_docked.loc[index_train].values\n",
    "    X_test = rfv2_features_docked.loc[fold].values\n",
    "    y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_features=14, n_jobs=6, random_state=42) #mtry=14 for rfv2\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "    fold_mse.append(mean_squared_error(y_test, pred))\n",
    "rfv2_cv_docked_results = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}\n",
    "\n",
    "print('RFv2 rdk crytsal')\n",
    "fold_pearsonr = []\n",
    "fold_mse = []\n",
    "for fold in folds:\n",
    "    index_train = pdbbind_training_set.difference(fold)\n",
    "    X_train = rfv2_rdk_features_crystal.loc[index_train].values\n",
    "    X_test = rfv2_rdk_features_crystal.loc[fold].values\n",
    "    y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42) #mtry=14 for rfv2\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "    fold_mse.append(mean_squared_error(y_test, pred))\n",
    "rfv2_rdk_cv_crystal_results = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}\n",
    "\n",
    "print('RFv2 rdk docked')\n",
    "fold_pearsonr = []\n",
    "fold_mse = []\n",
    "for fold in folds:\n",
    "    index_train = pdbbind_training_set.difference(fold)\n",
    "    X_train = rfv2_rdk_features_docked.loc[index_train].values\n",
    "    X_test = rfv2_rdk_features_docked.loc[fold].values\n",
    "    y_train = pdbbind_training_set_pk.loc[index_train].values.ravel()\n",
    "    y_test = pdbbind_training_set_pk.loc[fold].values.ravel()\n",
    "    rf = RandomForestRegressor(n_estimators=500, max_features=0.33, n_jobs=6, random_state=42) #mtry=14 for rfv2\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    fold_pearsonr.append(stats.pearsonr(y_test, pred)[0])\n",
    "    fold_mse.append(mean_squared_error(y_test, pred))\n",
    "rfv2_rdk_cv_docked_results = {'pearsonr': np.mean(fold_pearsonr), 'rmse': np.sqrt(np.mean(fold_mse)), 'pearsonr_stdev': np.std(fold_pearsonr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
